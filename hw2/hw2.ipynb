{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Машинное Обучения\n",
    "\n",
    "## Домашнее задание №2 - Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 1 февраля 2023, 08:30   \n",
    "**Штраф за опоздание:** -2 балла за каждые 2 дня опоздания\n",
    "\n",
    "Решений залить в свой github репозиторий.\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем дерево решений (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
    "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс MyDecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict . (Но название класса не менять)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from numba import njit, prange, NumbaPendingDeprecationWarning\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore', category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(nogil=True)\n",
    "def div_samples(x:np.ndarray, y:np.ndarray, feature_id:int, threshold:float):\n",
    "    \"\"\"\n",
    "    Разделяет объекты на 2 множества\n",
    "    x -- матрица объектов\n",
    "    y -- вектор ответов\n",
    "    feature_id -- айдишник признака, по которому делаем сплит\n",
    "    threshold -- порог, по которому делаем сплит\n",
    "    \"\"\"\n",
    "    left_mask = x[:, feature_id] > threshold\n",
    "    right_mask = ~left_mask\n",
    "    return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "@njit(nogil=True)\n",
    "def div_targets(x:np.ndarray, y:np.ndarray, feature_id:int, threshold:float):\n",
    "    \"\"\"\n",
    "    Разделяет ответы на 2 множества\n",
    "    x -- матрица объектов\n",
    "    y -- вектор ответов\n",
    "    feature_id -- айдишник признака, по которому делаем сплит\n",
    "    threshold -- порог, по которому делаем сплит\n",
    "    \"\"\"\n",
    "    left_mask = x[:, feature_id] > threshold\n",
    "    right_mask = ~left_mask\n",
    "    return y[left_mask], y[right_mask]\n",
    "    \n",
    "@njit(nogil=True)\n",
    "def gini_criterion(cnt, len_):\n",
    "    if(len_==0): return 1\n",
    "    return 1 - sum([(c/len_)**2 for c in cnt])\n",
    "    \n",
    "@njit(nogil=True)\n",
    "def entropy_criterion(cnt, len_):\n",
    "    if(len_==0): return 0\n",
    "    return -sum([c/len_*np.log(c/len_) for c in cnt])\n",
    "    \n",
    "@njit(nogil=True)\n",
    "def log_loss_criterion(cnt, len_):\n",
    "    if(len_==0): return 1\n",
    "    return 1 - cnt.max()/len_\n",
    "\n",
    "@njit(nogil=True)\n",
    "def find_threshold_njit(x, y, j, y_criterion, l_mem, r_mem, thresholds, counts):\n",
    "    l, r = l_mem.copy(), r_mem.copy()\n",
    "    len_l, len_r = 0, len(y)\n",
    "    mx_gain, mx_thr = 0, 0\n",
    "    whole_y = y_criterion(r, len(y))\n",
    "    # print(whole_y)\n",
    "            \n",
    "    for i in range(len(thresholds)):\n",
    "        threshold, target = thresholds[i]\n",
    "        target=int(target)\n",
    "        l[target]+=counts[i]\n",
    "        r[target]-=counts[i]\n",
    "        len_l += counts[i]\n",
    "        len_r -= counts[i]\n",
    "        if(i!=len(thresholds)-1 and thresholds[i+1][0]==threshold): continue\n",
    "        gain = -y_criterion(l, len_l)*len_l/len(y) - y_criterion(r, len_r)*len_r/len(y) + whole_y\n",
    "        # print(threshold, gain, len_l, len_r, l, r, thresholds, counts)\n",
    "        if(gain>mx_gain):\n",
    "            mx_gain = gain\n",
    "            mx_thr = threshold\n",
    "    return mx_gain, mx_thr\n",
    "\n",
    "@njit(nogil=True)\n",
    "def find_threshold_njit_loop(x, y, y_criterion, l_mem, r_mem, uniques):\n",
    "    mx_gain, mx_j, mx_thr = -1, 0, 0\n",
    "    for j in range(x.shape[1]):\n",
    "        thresholds, counts = uniques[j]\n",
    "        gain, threshold = find_threshold_njit(x, y, j, y_criterion, l_mem, r_mem, thresholds, counts)\n",
    "        if(gain>mx_gain):\n",
    "            mx_gain = gain\n",
    "            mx_j = j\n",
    "            mx_thr = threshold\n",
    "    return mx_gain, mx_j, mx_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=5, criterion='gini'):\n",
    "        \"\"\"\n",
    "        criterion -- критерий расщепления. необходимо релизовать три:\n",
    "        Ошибка классификации, Индекс Джини, Энтропийный критерий\n",
    "        max_depth -- максимальная глубина дерева\n",
    "        min_samples_split -- минимальное число объектов в листе, чтобы сделать новый сплит\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.num_class = -1\n",
    "        # Для последнего задания\n",
    "        self.feature_importances_ = None\n",
    "        self.criterion = criterion\n",
    "        # Структура, которая описывает дерево\n",
    "        # Представляет словарь, где для  node_id (айдишник узла дерева) храним\n",
    "        # (тип_узла, айдишник признака сплита, порог сплита) если тип NON_LEAF_TYPE\n",
    "        # (тип_узла, предсказание класса, вероятность класса) если тип LEAF_TYPE\n",
    "        # Подразумевается, что у каждого node_id в дереве слева \n",
    "        # узел с айди 2 * node_id + 1, а справа 2 * node_id + 2\n",
    "        self.tree = {}\n",
    "    \n",
    "    def __gini_criterion(self, cnt, len_):\n",
    "        if(len_==0): return 1\n",
    "        return 1 - sum([(c/len_)**2 for c in cnt])\n",
    "    \n",
    "    def __entropy_criterion(self, cnt, len_):\n",
    "        if(len_==0): return 0\n",
    "        return -sum([c/len_*np.log(c/len_) for c in cnt])\n",
    "    \n",
    "    def __log_loss_criterion(self, cnt, len_):\n",
    "        if(len_==0): return 1\n",
    "        return 1 - cnt.max()/len_\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        \"\"\"\n",
    "        Находим оптимальный признак и порог для сплита\n",
    "        Здесь используемые разные impurity в зависимости от self.criterion\n",
    "        \"\"\"\n",
    "        mx_gain, mx_j, mx_thr = -1, 0, 0\n",
    "        y_criterion = None\n",
    "        if(self.criterion=='gini'):\n",
    "            y_criterion = gini_criterion\n",
    "        elif(self.criterion=='entropy'):\n",
    "            y_criterion = entropy_criterion\n",
    "        else:    \n",
    "            y_criterion = log_loss_criterion\n",
    "        \n",
    "        l_mem = np.array([0 for i in range(self.num_class)])\n",
    "        uniq = np.unique(y)\n",
    "        r_mem = np.array([sum(y==c) for c in range(self.num_class)])\n",
    "        \n",
    "        uniques = [np.unique(list(zip(x[:,j], y)), axis=0, return_counts=True) for j in range(x.shape[1])]\n",
    "                \n",
    "        return find_threshold_njit_loop(x, y, y_criterion, l_mem, r_mem, uniques)\n",
    "                    \n",
    "            \n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \"\"\"\n",
    "        Делаем новый узел в дереве\n",
    "        Решаем, терминальный он или нет\n",
    "        Если нет, то строим левый узел  с айди 2 * node_id + 1\n",
    "        И правый узел с  айди 2 * node_id + 2\n",
    "        \"\"\"\n",
    "        if(len(x)==0): return\n",
    "        self.tree[node_id] = [-1,-1,-1]\n",
    "        if(depth==self.max_depth or len(x) < self.min_samples_split):\n",
    "            self.tree[node_id][0] = self.__class__.LEAF_TYPE\n",
    "            ys, cnt = np.unique(y, return_counts=True)\n",
    "            ind_max = np.argmax(cnt)\n",
    "            self.tree[node_id][1] = ys[ind_max]\n",
    "            self.tree[node_id][2] = cnt[ind_max] / len(y)\n",
    "            return\n",
    "        \n",
    "        self.tree[node_id][0] = self.__class__.NON_LEAF_TYPE\n",
    "        gain, j, thr = self.__find_threshold(x, y)\n",
    "        self.feature_importances_[j] += gain\n",
    "        self.tree[node_id][1] = j\n",
    "        self.tree[node_id][2] = thr\n",
    "        if(gain==0): \n",
    "            self.tree[node_id][0] = self.__class__.LEAF_TYPE\n",
    "            ys, cnt = np.unique(y, return_counts=True)\n",
    "            ind_max = np.argmax(cnt)\n",
    "            self.tree[node_id][1] = ys[ind_max]\n",
    "            self.tree[node_id][2] = cnt[ind_max] / len(y)\n",
    "            return\n",
    "        \n",
    "        xl, xr, yl, yr = div_samples(x, y, j, thr)\n",
    "        \n",
    "        self.__fit_node(xl, yl, node_id * 2 + 1, depth+1)\n",
    "        self.__fit_node(xr, yr, node_id * 2 + 2, depth+1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Рекурсивно строим дерево решений\n",
    "        Начинаем с корня node_id 0\n",
    "        \"\"\"\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = [0 for i in range(x.shape[1])]\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        \"\"\"\n",
    "        Рекурсивно обходим дерево по всем узлам,\n",
    "        пока не дойдем до терминального\n",
    "        \"\"\"\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Вызывает predict для всех объектов из матрицы X\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def __predict_proba(self, x, node_id):\n",
    "        \"\"\"\n",
    "        Рекурсивно обходим дерево по всем узлам,\n",
    "        пока не дойдем до терминального\n",
    "        \"\"\"\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_proba(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_proba(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Вызывает predict_proba для всех объектов из матрицы X\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_proba(x, 0) for x in X])\n",
    "    \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Возвращает важность признаков\n",
    "        \"\"\"\n",
    "        return np.array(self.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7361282367447596\n",
      "0.8199753390875463\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=3, criterion='entropy')\n",
    "clf = DecisionTreeClassifier(min_samples_split=3, criterion='entropy')\n",
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, criterion='log_loss')\n",
    "clf = DecisionTreeClassifier(min_samples_split=2, criterion='log_loss')\n",
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет: Проверьте, что ваша реализация корректно работает с признаками в которых встречаются повторы. \n",
    "И подумайте, какие еще граничные случаи могут быть.\n",
    "Например, проверьте, что на таком примере ваша модель корректно работает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPTH: 1 \n",
      "\t\tTree: {0: [0, 1, 2], 1: [1, 1, 0.7142857142857143], 2: [1, 0, 1.0]} [0 0 0 1 1 1 1 1 1 1]\n",
      "DEPTH: 2 \n",
      "\t\tTree: {0: [0, 1, 2], 1: [0, 1, 6], 3: [1, 1, 1.0], 4: [1, 0, 0.5], 2: [1, 0, 1.0]} [0 0 0 0 0 0 0 1 1 1]\n",
      "DEPTH: 3 \n",
      "\t\tTree: {0: [0, 1, 2], 1: [0, 1, 6], 3: [1, 1, 1.0], 4: [0, 1, 4], 9: [1, 0, 1.0], 10: [1, 1, 1.0], 2: [1, 0, 1.0]} [0 0 0 0 0 1 1 1 1 1]\n",
      "DEPTH: 4 \n",
      "\t\tTree: {0: [0, 1, 2], 1: [0, 1, 6], 3: [1, 1, 1.0], 4: [0, 1, 4], 9: [1, 0, 1.0], 10: [1, 1, 1.0], 2: [1, 0, 1.0]} [0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1] * 10, [0, 1, 2, 5, 6, 3, 4, 7, 8, 9]]).T\n",
    "y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "for depth in range(1, 5):\n",
    "    my_clf = MyDecisionTreeClassifier(max_depth=depth)\n",
    "    my_clf.fit(X, y)\n",
    "    print(\"DEPTH:\", depth, \"\\n\\t\\tTree:\", my_clf.tree, my_clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Придумайте интересные примеры для отладки дерева решений (доп. задание)\n",
    "Это необязательный пункт. За него можно получить 1 доп балл. \n",
    "Можете придумать примеры для отладки дерева, похожие на пример выше. \n",
    "\n",
    "Они должны быть не сложные, но в то же время информативные, чтобы можно было понять, что реализация содержит ошибки.\n",
    "Вместе с примером нужно указать ожидаемый выход модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускоряем дерево решений (2 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine. \n",
    "Для этого используем numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.26 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "2.9 ms ± 1.59 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 10 \n",
    "clf = DecisionTreeClassifier(min_samples_split=2, max_depth=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.4 ms ± 5.82 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 10 \n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2, max_depth=5)\n",
    "my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Боевое применение (3 балла)\n",
    "\n",
    "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match). \n",
    "\n",
    "Данные и описания колонок во вложениях.\n",
    "\n",
    "Пример работы с датасетом можете найти в практике пункт 2\n",
    "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
    "\n",
    "Либо воспользоваться функцией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_spd_data(df):\n",
    "    df = df.iloc[:, :97]\n",
    "    \n",
    "    to_drop = [\n",
    "        'id', 'idg', 'condtn', 'round', 'position', 'positin1', 'order', 'partner', \n",
    "        'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha',\n",
    "        'dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o','met_o',\n",
    "        'field', 'undergra', 'from', 'zipcode', 'income', 'career', 'sports', 'tvsports', 'exercise', \n",
    "        'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', \n",
    "        'concerts', 'music', 'shopping', 'yoga', 'expnum',\n",
    "        'mn_sat', 'tuition'\n",
    "    ]\n",
    "\n",
    "    df = df.drop(to_drop, axis=1)\n",
    "    df = df.dropna(subset=['age', 'imprelig', 'imprace', 'date'])\n",
    "\n",
    "    df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(19)\n",
    "    df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(18)\n",
    "    \n",
    "    # attr1 processing\n",
    "    df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', \n",
    "                                            'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "    df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']] =\\\n",
    "    (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].T / \n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "    \n",
    "    # attr2 processing\n",
    "    df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', \n",
    "                                            'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "    df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']] =\\\n",
    "    (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].T / \n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "    df = df.drop(['temp_totalsum'], axis=1)\n",
    "    \n",
    "    for i in [4, 5]:\n",
    "        feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i), \n",
    "                'intel{}_1'.format(i), 'fun{}_1'.format(i), \n",
    "                'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "\n",
    "        if i != 4:\n",
    "            feat.remove('shar{}_1'.format(i))\n",
    "    \n",
    "        df = df.drop(feat, axis=1)\n",
    "    \n",
    "    df = df.drop(['wave'], axis=1)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. В качестве метрики можно взять roc-auc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>gender</th>\n",
       "      <th>pid</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>race</th>\n",
       "      <th>imprace</th>\n",
       "      <th>...</th>\n",
       "      <th>sinc2_1</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>526.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>527.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>528.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>530.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8104 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid  gender    pid  match  int_corr  samerace   age  field_cd  race  \\\n",
       "0       1       0   11.0      0      0.14         0  21.0       1.0   4.0   \n",
       "1       1       0   12.0      0      0.54         0  21.0       1.0   4.0   \n",
       "2       1       0   13.0      1      0.16         1  21.0       1.0   4.0   \n",
       "3       1       0   14.0      1      0.61         0  21.0       1.0   4.0   \n",
       "4       1       0   15.0      1      0.21         0  21.0       1.0   4.0   \n",
       "...   ...     ...    ...    ...       ...       ...   ...       ...   ...   \n",
       "8373  552       1  526.0      0      0.64         0  25.0      18.0   2.0   \n",
       "8374  552       1  527.0      0      0.71         0  25.0      18.0   2.0   \n",
       "8375  552       1  528.0      0     -0.46         0  25.0      18.0   2.0   \n",
       "8376  552       1  529.0      0      0.62         0  25.0      18.0   2.0   \n",
       "8377  552       1  530.0      0      0.01         0  25.0      18.0   2.0   \n",
       "\n",
       "      imprace  ...  sinc2_1  intel2_1  fun2_1  amb2_1  shar2_1  attr3_1  \\\n",
       "0         2.0  ...     20.0      15.0    20.0     5.0      5.0      6.0   \n",
       "1         2.0  ...     20.0      15.0    20.0     5.0      5.0      6.0   \n",
       "2         2.0  ...     20.0      15.0    20.0     5.0      5.0      6.0   \n",
       "3         2.0  ...     20.0      15.0    20.0     5.0      5.0      6.0   \n",
       "4         2.0  ...     20.0      15.0    20.0     5.0      5.0      6.0   \n",
       "...       ...  ...      ...       ...     ...     ...      ...      ...   \n",
       "8373      1.0  ...      0.0       0.0    30.0     0.0     20.0      8.0   \n",
       "8374      1.0  ...      0.0       0.0    30.0     0.0     20.0      8.0   \n",
       "8375      1.0  ...      0.0       0.0    30.0     0.0     20.0      8.0   \n",
       "8376      1.0  ...      0.0       0.0    30.0     0.0     20.0      8.0   \n",
       "8377      1.0  ...      0.0       0.0    30.0     0.0     20.0      8.0   \n",
       "\n",
       "      sinc3_1  fun3_1  intel3_1  amb3_1  \n",
       "0         8.0     8.0       8.0     7.0  \n",
       "1         8.0     8.0       8.0     7.0  \n",
       "2         8.0     8.0       8.0     7.0  \n",
       "3         8.0     8.0       8.0     7.0  \n",
       "4         8.0     8.0       8.0     7.0  \n",
       "...       ...     ...       ...     ...  \n",
       "8373      7.0     6.0       7.0     7.0  \n",
       "8374      7.0     6.0       7.0     7.0  \n",
       "8375      7.0     6.0       7.0     7.0  \n",
       "8376      7.0     6.0       7.0     7.0  \n",
       "8377      7.0     6.0       7.0     7.0  \n",
       "\n",
       "[8104 rows x 33 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Speed_Dating_Data.csv', encoding='latin1')\n",
    "df = preprocess_spd_data(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X,df_y = df.drop(['match'], axis=1, inplace=False), df.match\n",
    "X,y = df_X.to_numpy(), df_y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте датасет на трейн и валидацию. Подберите на валидации оптимальный критерий  информативности. \n",
    "Постройте графики зависимости точности на валидации и трейне от глубины дерева, от минимального числа объектов для сплита. (Т.е должно быть 2 графика, на каждой должны быть 2 кривые - для трейна и валидации)\n",
    "Какой максимальной точности удалось достигнуть?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC score:0.6072664538057472\n"
     ]
    }
   ],
   "source": [
    "model = MyDecisionTreeClassifier(min_samples_split=20, max_depth=20, criterion='entropy')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "print(f\"ROC-AUC score:{roc_auc_score(y_test, 1-y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gini 0.7718865598027127\n",
      "entropy 0.7928483353884094\n",
      "log_loss 0.8187422934648582\n"
     ]
    }
   ],
   "source": [
    "model = MyDecisionTreeClassifier(min_samples_split=20, max_depth=20, criterion='gini')\n",
    "model.fit(X_train, y_train)\n",
    "print('gini', accuracy_score(y_pred=model.predict(X_test), y_true=y_test))\n",
    "model = MyDecisionTreeClassifier(min_samples_split=20, max_depth=20, criterion='entropy')\n",
    "model.fit(X_train, y_train)\n",
    "print('entropy', accuracy_score(y_pred=model.predict(X_test), y_true=y_test))\n",
    "model = MyDecisionTreeClassifier(min_samples_split=20, max_depth=20, criterion='log_loss')\n",
    "model.fit(X_train, y_train)\n",
    "print('log_loss', accuracy_score(y_pred=model.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAGdCAYAAAASUnlxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6x0lEQVR4nO3df1RVZaL/8c/hJAiIoKNwDv5AShszA0dIEyMdRzGGYaqpuaTdFFLXOOa4uJhdiTvqmOMpM2cmHOnWlDeKGpcOdbsjaZhCetUbw8LRhY55C0PsICM3ASVBYX//8OsZTxyUQyXCfr/W2kvOs5/9PM9+2q3zWc8+Zx+LYRiGAAAATMCnqwcAAABwvRB8AACAaRB8AACAaRB8AACAaRB8AACAaRB8AACAaRB8AACAaRB8AACAadzU1QO4kbS2turzzz9XUFCQLBZLVw8HAAB0gGEYamhoUHh4uHx8rr6mQ/C5wueff64hQ4Z09TAAAEAnnDhxQoMHD75qHYLPFYKCgiRdmri+fft28WgAAEBH1NfXa8iQIa738ash+Fzh8u2tvn37EnwAAOhmOvIxFT7cDAAATIPgAwAATIPgAwAATIPgAwAATIPgAwAATIPgAwAATIPgAwAATIPgAwAATIPgAwAATIPgAwAATIPgAwAATIPgAwAATIMfKb0OLra06tcFR7p6GF3GIov8evnI7yYf+d7kI7+brFf8fXmzuu/v5SNfq88V/17af5OPpUM/QgcAgCcEn+ug1ZA2/vfxrh5Gj2CxyBWULgcnz2HK+o9QdUV48rW2LbuyjSvDmO9X27liv48P4QsAuiOCz3XgY5Ee//4tXT2MLtPSKjVfbFVzS4uaLrSq6WKrmi+2qulii5pbWtuU/ePvS68vtBiutgxDOn+hVecvtHbhGUm9rBYPwan9EHbV/b2s8nNb3bpUx0q4AtADWSSNv/k7XdY/wec6uMnqoyXTR3b1MLqt1lbjHwHp/4enfwSmlitCkqfwdEX9r5Q1tdtG2/DVdLFVxj/yly60GLrQ0qJzzS1dNzEA0A353uSjj1cldln/BB/c8Hx8LOrtY1XvXlZJvbpkDIZh6GKr4TlQeQhPnlauXH9f+Mfql9vxV6x+NV1sUUurce2BAUA308vatd+rIvgAHWCxWNTLarn0P6xfV48GANBZfJ0dAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYRqeCz4YNGxQZGanevXsrJiZGu3fvvmr9vLw8RUdHKyAgQHa7XWlpaaqtrXXtz8/PV2xsrEJCQhQYGKgxY8bo9ddfd2tj2LBhslgsbbbHH3/cVSc1NbXN/rvuuqszpwgAAHogr4PPpk2blJ6erqysLJWVlSk+Pl6JiYmqrKz0WH/Pnj2aNWuW5syZo/Lycm3evFklJSWaO3euq07//v2VlZWlffv26eDBg0pLS1NaWpq2b9/uqlNSUiKn0+naCgsLJUk//elP3fq799573eoVFBR4e4oAAKCHshiG4dVPQI8fP15jx45VTk6Oq+y2227T/fffL4fD0ab+2rVrlZOTo08++cRVlp2drTVr1ujEiRPt9jN27FglJSXp6aef9rg/PT1df/7zn3Xs2DFZLBZJl1Z8zpw5o3feecebU3Kpr69XcHCw6urq1Ldv3061AQAAri9v3r+9WvFpbm5WaWmpEhIS3MoTEhK0d+9ej8fExcWpqqpKBQUFMgxDp06d0pYtW5SUlOSxvmEY+uCDD3T06FHdc8897Y7jjTfe0GOPPeYKPZcVFRUpNDRUt956q+bNm6eampp2z6epqUn19fVuGwAA6Lm8Cj6nT59WS0uLwsLC3MrDwsJUXV3t8Zi4uDjl5eUpJSVFvr6+stlsCgkJUXZ2tlu9uro69enTR76+vkpKSlJ2dramTZvmsc133nlHZ86cUWpqqlt5YmKi8vLytHPnTj3//PMqKSnRlClT1NTU5LEdh8Oh4OBg1zZkyJAOzgQAAOiOOvXh5q+ushiG0absssOHD2vRokVatmyZSktLtW3bNlVUVGj+/Plu9YKCgnTgwAGVlJTo17/+tTIyMlRUVOSxzVdeeUWJiYkKDw93K09JSVFSUpJGjx6t5ORkvffee/r444+1detWj+1kZmaqrq7OtV3t1hsAAOj+bvKm8oABA2S1Wtus7tTU1LRZBbrM4XBo4sSJWrJkiSQpKipKgYGBio+P16pVq2S32yVJPj4+Gj58uCRpzJgxOnLkiBwOhyZPnuzW3meffaYdO3YoPz//muO12+2KiIjQsWPHPO738/OTn5/fNdsBAAA9g1crPr6+voqJiXF9o+qywsJCxcXFeTymsbFRPj7u3VitVkmXVoraYxiGx1tUGzduVGhoaLufEbpSbW2tTpw44QpXAADA3Lxa8ZGkjIwMPfroo4qNjdWECRP00ksvqbKy0nXrKjMzUydPnlRubq4kKTk5WfPmzVNOTo6mT58up9Op9PR0jRs3znWryuFwKDY2Vrfccouam5tVUFCg3Nxct2+OSVJra6s2btyo2bNn66ab3Id+9uxZrVixQg8++KDsdruOHz+up556SgMGDNADDzzQqckBAAA9i9fBJyUlRbW1tVq5cqWcTqdGjx6tgoICRURESJKcTqfbM31SU1PV0NCg9evXa/HixQoJCdGUKVP07LPPuuqcO3dOCxYsUFVVlfz9/TVy5Ei98cYbSklJcet7x44dqqys1GOPPdZmXFarVYcOHVJubq7OnDkju92u73//+9q0aZOCgoK8PU0AANADef0cn56M5/gAAND9fGvP8QEAAOjOCD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0OhV8NmzYoMjISPXu3VsxMTHavXv3Vevn5eUpOjpaAQEBstvtSktLU21trWt/fn6+YmNjFRISosDAQI0ZM0avv/66WxsrVqyQxWJx22w2m1sdwzC0YsUKhYeHy9/fX5MnT1Z5eXlnThEAAPRAXgefTZs2KT09XVlZWSorK1N8fLwSExNVWVnpsf6ePXs0a9YszZkzR+Xl5dq8ebNKSko0d+5cV53+/fsrKytL+/bt08GDB5WWlqa0tDRt377dra3bb79dTqfTtR06dMht/5o1a7Ru3TqtX79eJSUlstlsmjZtmhoaGrw9TQAA0BMZXho3bpwxf/58t7KRI0caS5cu9Vj/ueeeM26++Wa3shdeeMEYPHjwVfv53ve+Z/zbv/2b6/Xy5cuN6Ojoduu3trYaNpvNeOaZZ1xl58+fN4KDg40XX3zxqn1dVldXZ0gy6urqOlQfAAB0PW/ev71a8WlublZpaakSEhLcyhMSErR3716Px8TFxamqqkoFBQUyDEOnTp3Sli1blJSU1F4Q0wcffKCjR4/qnnvucdt37NgxhYeHKzIyUg8//LA+/fRT176KigpVV1e7jc3Pz0+TJk1qd2wAAMBcbvKm8unTp9XS0qKwsDC38rCwMFVXV3s8Ji4uTnl5eUpJSdH58+d18eJF/fjHP1Z2drZbvbq6Og0aNEhNTU2yWq3asGGDpk2b5to/fvx45ebm6tZbb9WpU6e0atUqxcXFqby8XN/5zndc/Xsa22effeZxbE1NTWpqanK9rq+v7/hkAACAbqdTH262WCxurw3DaFN22eHDh7Vo0SItW7ZMpaWl2rZtmyoqKjR//ny3ekFBQTpw4IBKSkr061//WhkZGSoqKnLtT0xM1IMPPqg77rhDU6dO1datWyVJr732WqfH5nA4FBwc7NqGDBnSofMHAADdk1crPgMGDJDVam2zulNTU9NmpeUyh8OhiRMnasmSJZKkqKgoBQYGKj4+XqtWrZLdbpck+fj4aPjw4ZKkMWPG6MiRI3I4HJo8ebLHdgMDA3XHHXfo2LFjkuT6hld1dbWrzWuNLTMzUxkZGa7X9fX1hB8AAHowr1Z8fH19FRMTo8LCQrfywsJCxcXFeTymsbFRPj7u3VitVkmXVmPaYxiG222or2pqatKRI0dcIScyMlI2m81tbM3NzSouLm53bH5+furbt6/bBgAAei6vVnwkKSMjQ48++qhiY2M1YcIEvfTSS6qsrHTdusrMzNTJkyeVm5srSUpOTta8efOUk5Oj6dOny+l0Kj09XePGjVN4eLikS6tCsbGxuuWWW9Tc3KyCggLl5uYqJyfH1e8TTzyh5ORkDR06VDU1NVq1apXq6+s1e/ZsSZducaWnp2v16tUaMWKERowYodWrVysgIEAzZ8782hMFAAC6P6+DT0pKimpra7Vy5Uo5nU6NHj1aBQUFioiIkCQ5nU63Z/qkpqaqoaFB69ev1+LFixUSEqIpU6bo2WefddU5d+6cFixYoKqqKvn7+2vkyJF64403lJKS4qpTVVWlGTNm6PTp0xo4cKDuuusu7d+/39WvJD355JP68ssvtWDBAn3xxRcaP3683n//fQUFBXVqcgAAQM9iMa52v8lk6uvrFRwcrLq6Om57AQDQTXjz/s1vdQEAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANPoVPDZsGGDIiMj1bt3b8XExGj37t1XrZ+Xl6fo6GgFBATIbrcrLS1NtbW1rv35+fmKjY1VSEiIAgMDNWbMGL3++utubTgcDt15550KCgpSaGio7r//fh09etStTmpqqiwWi9t21113deYUAQBAD+R18Nm0aZPS09OVlZWlsrIyxcfHKzExUZWVlR7r79mzR7NmzdKcOXNUXl6uzZs3q6SkRHPnznXV6d+/v7KysrRv3z4dPHhQaWlpSktL0/bt2111iouL9fjjj2v//v0qLCzUxYsXlZCQoHPnzrn1d++998rpdLq2goICb08RAAD0UBbDMAxvDhg/frzGjh2rnJwcV9ltt92m+++/Xw6Ho039tWvXKicnR5988omrLDs7W2vWrNGJEyfa7Wfs2LFKSkrS008/7XH/3//+d4WGhqq4uFj33HOPpEsrPmfOnNE777zjzSm51NfXKzg4WHV1derbt2+n2gAAANeXN+/fXq34NDc3q7S0VAkJCW7lCQkJ2rt3r8dj4uLiVFVVpYKCAhmGoVOnTmnLli1KSkryWN8wDH3wwQc6evSoK9B4UldXJ+nSatGVioqKFBoaqltvvVXz5s1TTU1Nu200NTWpvr7ebQMAAD2XV8Hn9OnTamlpUVhYmFt5WFiYqqurPR4TFxenvLw8paSkyNfXVzabTSEhIcrOznarV1dXpz59+sjX11dJSUnKzs7WtGnTPLZpGIYyMjJ09913a/To0a7yxMRE5eXlaefOnXr++edVUlKiKVOmqKmpyWM7DodDwcHBrm3IkCHeTAcAAOhmOvXhZovF4vbaMIw2ZZcdPnxYixYt0rJly1RaWqpt27apoqJC8+fPd6sXFBSkAwcOqKSkRL/+9a+VkZGhoqIij20uXLhQBw8e1FtvveVWnpKSoqSkJI0ePVrJycl677339PHHH2vr1q0e28nMzFRdXZ1ru9qtNwAA0P3d5E3lAQMGyGq1tlndqampabMKdJnD4dDEiRO1ZMkSSVJUVJQCAwMVHx+vVatWyW63S5J8fHw0fPhwSdKYMWN05MgRORwOTZ482a29X/ziF3r33Xf14YcfavDgwVcdr91uV0REhI4dO+Zxv5+fn/z8/K553gAAoGfwasXH19dXMTExKiwsdCsvLCxUXFycx2MaGxvl4+PejdVqlXRppag9hmG43aIyDEMLFy5Ufn6+du7cqcjIyGuOt7a2VidOnHCFKwAAYG5erfhIUkZGhh599FHFxsZqwoQJeumll1RZWem6dZWZmamTJ08qNzdXkpScnKx58+YpJydH06dPl9PpVHp6usaNG6fw8HBJl1aFYmNjdcstt6i5uVkFBQXKzc11++bY448/rjfffFP/+Z//qaCgINeqU3BwsPz9/XX27FmtWLFCDz74oOx2u44fP66nnnpKAwYM0AMPPPC1JwoAAHR/XgeflJQU1dbWauXKlXI6nRo9erQKCgoUEREhSXI6nW7P9ElNTVVDQ4PWr1+vxYsXKyQkRFOmTNGzzz7rqnPu3DktWLBAVVVV8vf318iRI/XGG28oJSXFVedyCPrqra+NGzcqNTVVVqtVhw4dUm5urs6cOSO73a7vf//72rRpk4KCgrw9TQAA0AN5/Ryfnozn+AAA0P18a8/xAQAA6M4IPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQIPgAAwDQ6FXw2bNigyMhI9e7dWzExMdq9e/dV6+fl5Sk6OloBAQGy2+1KS0tTbW2ta39+fr5iY2MVEhKiwMBAjRkzRq+//rrX/RqGoRUrVig8PFz+/v6aPHmyysvLO3OKAACgB/I6+GzatEnp6enKyspSWVmZ4uPjlZiYqMrKSo/19+zZo1mzZmnOnDkqLy/X5s2bVVJSorlz57rq9O/fX1lZWdq3b58OHjyotLQ0paWlafv27V71u2bNGq1bt07r169XSUmJbDabpk2bpoaGBm9PEwAA9EAWwzAMbw4YP368xo4dq5ycHFfZbbfdpvvvv18Oh6NN/bVr1yonJ0effPKJqyw7O1tr1qzRiRMn2u1n7NixSkpK0tNPP92hfg3DUHh4uNLT0/Wv//qvkqSmpiaFhYXp2Wef1c9+9rNrnlt9fb2Cg4NVV1envn37XnsyAADooJaWFl24cKGrh9Ft9erVS1ar1eM+b96/b/Km0+bmZpWWlmrp0qVu5QkJCdq7d6/HY+Li4pSVlaWCggIlJiaqpqZGW7ZsUVJSksf6hmFo586dOnr0qJ599tkO91tRUaHq6molJCS49vv5+WnSpEnau3evx+DT1NSkpqYm1+v6+voOzAIAAB1nGIaqq6t15syZrh5KtxcSEiKbzSaLxdLpNrwKPqdPn1ZLS4vCwsLcysPCwlRdXe3xmLi4OOXl5SklJUXnz5/XxYsX9eMf/1jZ2dlu9erq6jRo0CA1NTXJarVqw4YNmjZtWof7vfyvpzqfffaZx7E5HA796le/6uDZAwDgvcuhJzQ0VAEBAV/rTdusDMNQY2OjampqJEl2u73TbXkVfC776n80wzDa/Q95+PBhLVq0SMuWLdP06dPldDq1ZMkSzZ8/X6+88oqrXlBQkA4cOKCzZ8/qgw8+UEZGhm6++WZNnjzZq369GVtmZqYyMjJcr+vr6zVkyJD2TxwAAC+0tLS4Qs93vvOdrh5Ot+bv7y9JqqmpUWhoaLu3va7Fq+AzYMAAWa3WNqs7NTU1bVZaLnM4HJo4caKWLFkiSYqKilJgYKDi4+O1atUqV2rz8fHR8OHDJUljxozRkSNH5HA4NHny5A71a7PZJF1K1lcmwauNzc/PT35+ft5MAQAAHXb5Mz0BAQFdPJKe4fI8XrhwodPBx6tvdfn6+iomJkaFhYVu5YWFhYqLi/N4TGNjo3x83Lu5PNirfa7aMAzX52860m9kZKRsNptbnebmZhUXF7c7NgAArgdub30zvol59PpWV0ZGhh599FHFxsZqwoQJeumll1RZWan58+dLunT76OTJk8rNzZUkJScna968ecrJyXHd6kpPT9e4ceMUHh4u6dKqUGxsrG655RY1NzeroKBAubm5bt/gula/FotF6enpWr16tUaMGKERI0Zo9erVCggI0MyZM7/2RAEAgO7P6+CTkpKi2tparVy5Uk6nU6NHj1ZBQYEiIiIkSU6n0+3ZOqmpqWpoaND69eu1ePFihYSEaMqUKa5vbEnSuXPntGDBAlVVVcnf318jR47UG2+8oZSUlA73K0lPPvmkvvzySy1YsEBffPGFxo8fr/fff19BQUGdmhwAAPD1DRs2TOnp6UpPT+/qoXj/HJ+ejOf4AAC+SefPn1dFRYXrVwe6k8mTJ2vMmDH67W9/+7Xb+vvf/67AwMCv/Vmn9ubzW3uODwAAgHTps7gtLS266aZrR4mBAwdehxF1DD9SCgAA3KSmpqq4uFi/+93vZLFYZLFY9B//8R+yWCzavn27YmNj5efnp927d+uTTz7Rfffdp7CwMPXp00d33nmnduzY4dbesGHD3FaOLBaL/vCHP+iBBx5QQECARowYoXffffe6nBvBBwCA68gwDDU2X7zumzefbPnd736nCRMmaN68eXI6nXI6na7n3D355JNyOBw6cuSIoqKidPbsWf3whz/Ujh07VFZWpunTpys5Obnd3/C87Fe/+pX+6Z/+SQcPHtQPf/hDPfLII/q///u/rzW3HcGtLgAArqMvL7Ro1LLt1674DTu8croCfDv2th8cHCxfX18FBAS4npP3t7/9TZK0cuVK1y8rSNJ3vvMdRUdHu16vWrVKb7/9tt59910tXLiw3T5SU1M1Y8YMSdLq1auVnZ2tjz76SPfee6/X5+YNVnwAAECHxcbGur0+d+6cnnzySY0aNUohISHq06eP/va3v11zxScqKsr1d2BgoIKCglw/SfFtYsUHAIDryL+XVYdXTu+Sfr8JgYGBbq+XLFmi7du3a+3atRo+fLj8/f310EMPqbm5+art9OrVy+21xWJRa2vrNzLGqyH4AABwHVkslg7fcupKvr6+amlpuWa93bt3KzU1VQ888IAk6ezZszp+/Pi3PLrO41YXAABoY9iwYfqf//kfHT9+XKdPn253NWb48OHKz8/XgQMH9Ne//lUzZ868Lis3nUXwAQAAbTzxxBOyWq0aNWqUBg4c2O5ndn7zm9+oX79+iouLU3JysqZPn66xY8de59F2HE9uvgJPbgYAfJO685Obb0TfxJObWfEBAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAADfuGHDhum3v/2t67XFYtE777zTbv3jx4/LYrHowIED3+q4bvyfhwUAAN2e0+lUv379unoYBB8AAPDts9lsXT0ESdzqAgAAX/Hv//7vGjRokFpbW93Kf/zjH2v27Nn65JNPdN999yksLEx9+vTRnXfeqR07dly1za/e6vroo4/0ve99T71791ZsbKzKysq+jVNpg+ADAMD1ZBhS87nrvxlGh4f405/+VKdPn9auXbtcZV988YW2b9+uRx55RGfPntUPf/hD7dixQ2VlZZo+fbqSk5NVWVnZofbPnTunH/3oR/rud7+r0tJSrVixQk888YTXU9kZ3OoCAOB6utAorQ6//v0+9bnkG9ihqv3799e9996rN998Uz/4wQ8kSZs3b1b//v31gx/8QFarVdHR0a76q1at0ttvv613331XCxcuvGb7eXl5amlp0auvvqqAgADdfvvtqqqq0s9//vPOnZsXWPEBAABtPPLII/rTn/6kpqYmSZfCysMPPyyr1apz587pySef1KhRoxQSEqI+ffrob3/7W4dXfI4cOaLo6GgFBAS4yiZMmPCtnMdXseIDAMD11Cvg0upLV/TrheTkZLW2tmrr1q268847tXv3bq1bt06StGTJEm3fvl1r167V8OHD5e/vr4ceekjNzc0datvw4rbbN43gAwDA9WSxdPiWU1fy9/fXT37yE+Xl5el///d/deuttyomJkaStHv3bqWmpuqBBx6QJJ09e1bHjx/vcNujRo3S66+/ri+//FL+/v6SpP3793/j5+AJt7oAAIBHjzzyiLZu3apXX31V//zP/+wqHz58uPLz83XgwAH99a9/1cyZM9t8A+xqZs6cKR8fH82ZM0eHDx9WQUGB1q5d+22cQhsEHwAA4NGUKVPUv39/HT16VDNnznSV/+Y3v1G/fv0UFxen5ORkTZ8+XWPHju1wu3369NF//dd/6fDhw/re976nrKwsPfvss9/GKbRhMbryRtsNpr6+XsHBwaqrq1Pfvn27ejgAgG7u/PnzqqioUGRkpHr37t3Vw+n22ptPb96/O7Xis2HDBlenMTEx2r1791Xr5+XluT69bbfblZaWptraWtf+l19+WfHx8erXr5/69eunqVOn6qOPPnJrY9iwYbJYLG22xx9/3FUnNTW1zf677rqrM6cIAAB6IK+Dz6ZNm5Senq6srCyVlZUpPj5eiYmJ7X6Fbc+ePZo1a5bmzJmj8vJybd68WSUlJZo7d66rTlFRkWbMmKFdu3Zp3759Gjp0qBISEnTy5ElXnZKSEjmdTtdWWFgo6dJDlq507733utUrKCjw9hQBAEAP5XXwWbdunebMmaO5c+fqtttu029/+1sNGTJEOTk5Huvv379fw4YN06JFixQZGam7775bP/vZz/SXv/zFVScvL08LFizQmDFjNHLkSL388stqbW3VBx984KozcOBA2Ww21/bnP/9Zt9xyiyZNmuTWn5+fn1u9/v37e3uKAACgh/Iq+DQ3N6u0tFQJCQlu5QkJCdq7d6/HY+Li4lRVVaWCggIZhqFTp05py5YtSkpKarefxsZGXbhwod3Q0tzcrDfeeEOPPfaYLBaL276ioiKFhobq1ltv1bx581RTU9NuP01NTaqvr3fbAABAz+VV8Dl9+rRaWloUFhbmVh4WFqbq6mqPx8TFxSkvL08pKSny9fWVzWZTSEiIsrOz2+1n6dKlGjRokKZOnepx/zvvvKMzZ84oNTXVrTwxMVF5eXnauXOnnn/+eZWUlGjKlCmup05+lcPhUHBwsGsbMmTIVc4eAAB0d536cPNXV1kMw2hTdtnhw4e1aNEiLVu2TKWlpdq2bZsqKio0f/58j/XXrFmjt956S/n5+e1+Av6VV15RYmKiwsPdf+skJSVFSUlJGj16tJKTk/Xee+/p448/1tatWz22k5mZqbq6Otd24sSJa506AABe4wvU34xvYh69enLzgAEDZLVa26zu1NTUtFkFuszhcGjixIlasmSJJCkqKkqBgYGKj4/XqlWrZLfbXXXXrl2r1atXa8eOHYqKivLY3meffaYdO3YoPz//muO12+2KiIjQsWPHPO738/OTn5/fNdsBAKAzevXqJenSRzguP6EYndfY2CjpH/PaGV4FH19fX8XExKiwsND1mGpJKiws1H333dfuIG+6yb0bq9UqyT25Pffcc1q1apW2b9+u2NjYdsewceNGhYaGXvUzQpfV1tbqxIkTbuEKAIDrxWq1KiQkxPV504CAgHbvkKB9hmGosbFRNTU1CgkJceWIzvD6t7oyMjL06KOPKjY2VhMmTNBLL72kyspK162rzMxMnTx5Urm5uZIu/cjZvHnzlJOTo+nTp8vpdCo9PV3jxo1z3apas2aNfvnLX+rNN9/UsGHDXCtKffr0UZ8+fVx9t7a2auPGjZo9e3abMHX27FmtWLFCDz74oOx2u44fP66nnnpKAwYMcAtpAABcTzabTZKu+mUbdExISIhrPjvL6+CTkpKi2tparVy5Uk6nU6NHj1ZBQYEiIiIkSU6n0+2ZPqmpqWpoaND69eu1ePFihYSEaMqUKW6Ppt6wYYOam5v10EMPufW1fPlyrVixwvV6x44dqqys1GOPPdZmXFarVYcOHVJubq7OnDkju92u73//+9q0aZOCgoK8PU0AAL4RFotFdrtdoaGhunDhQlcPp9vq1avX11rpuYyfrLgCP1kBAED3863/ZAUAAEB3RPABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACmQfABAACm0angs2HDBkVGRqp3796KiYnR7t27r1o/Ly9P0dHRCggIkN1uV1pammpra137X375ZcXHx6tfv37q16+fpk6dqo8++sitjRUrVshisbhtNpvNrY5hGFqxYoXCw8Pl7++vyZMnq7y8vDOnCAAAeiCvg8+mTZuUnp6urKwslZWVKT4+XomJiaqsrPRYf8+ePZo1a5bmzJmj8vJybd68WSUlJZo7d66rTlFRkWbMmKFdu3Zp3759Gjp0qBISEnTy5Em3tm6//XY5nU7XdujQIbf9a9as0bp167R+/XqVlJTIZrNp2rRpamho8PY0AQBAT2R4ady4ccb8+fPdykaOHGksXbrUY/3nnnvOuPnmm93KXnjhBWPw4MHt9nHx4kUjKCjIeO2111xly5cvN6Kjo9s9prW11bDZbMYzzzzjKjt//rwRHBxsvPjii1c7JZe6ujpDklFXV9eh+gAAoOt58/7t1YpPc3OzSktLlZCQ4FaekJCgvXv3ejwmLi5OVVVVKigokGEYOnXqlLZs2aKkpKR2+2lsbNSFCxfUv39/t/Jjx44pPDxckZGRevjhh/Xpp5+69lVUVKi6utptbH5+fpo0aVK7YwMAAObiVfA5ffq0WlpaFBYW5lYeFham6upqj8fExcUpLy9PKSkp8vX1lc1mU0hIiLKzs9vtZ+nSpRo0aJCmTp3qKhs/frxyc3O1fft2vfzyy6qurlZcXJzrs0KX+/dmbE1NTaqvr3fbAABAz9WpDzdbLBa314ZhtCm77PDhw1q0aJGWLVum0tJSbdu2TRUVFZo/f77H+mvWrNFbb72l/Px89e7d21WemJioBx98UHfccYemTp2qrVu3SpJee+21To/N4XAoODjYtQ0ZMuTqJw4AALo1r4LPgAEDZLVa26yg1NTUtFlpuczhcGjixIlasmSJoqKiNH36dG3YsEGvvvqqnE6nW921a9dq9erVev/99xUVFXXVsQQGBuqOO+7QsWPHJMn1DS9vxpaZmam6ujrXduLEiav2CQAAujevgo+vr69iYmJUWFjoVl5YWKi4uDiPxzQ2NsrHx70bq9Uq6dJqzGXPPfecnn76aW3btk2xsbHXHEtTU5OOHDkiu90uSYqMjJTNZnMbW3Nzs4qLi9sdm5+fn/r27eu2AQCAnusmbw/IyMjQo48+qtjYWE2YMEEvvfSSKisrXbeuMjMzdfLkSeXm5kqSkpOTNW/ePOXk5Gj69OlyOp1KT0/XuHHjFB4eLunS7a1f/vKXevPNNzVs2DDXqk2fPn3Up08fSdITTzyh5ORkDR06VDU1NVq1apXq6+s1e/ZsSZducaWnp2v16tUaMWKERowYodWrVysgIEAzZ878+jMFAAC6Pa+DT0pKimpra7Vy5Uo5nU6NHj1aBQUFioiIkCQ5nU63Z/qkpqaqoaFB69ev1+LFixUSEqIpU6bo2WefddXZsGGDmpub9dBDD7n1tXz5cq1YsUKSVFVVpRkzZuj06dMaOHCg7rrrLu3fv9/VryQ9+eST+vLLL7VgwQJ98cUXGj9+vN5//30FBQV5e5oAAKAHshhX3m8yufr6egUHB6uuro7bXgAAdBPevH/zW10AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0CD4AAMA0OhV8NmzYoMjISPXu3VsxMTHavXv3Vevn5eUpOjpaAQEBstvtSktLU21trWv/yy+/rPj4ePXr10/9+vXT1KlT9dFHH7m14XA4dOeddyooKEihoaG6//77dfToUbc6qampslgsbttdd93VmVMEAAA9kNfBZ9OmTUpPT1dWVpbKysoUHx+vxMREVVZWeqy/Z88ezZo1S3PmzFF5ebk2b96skpISzZ0711WnqKhIM2bM0K5du7Rv3z4NHTpUCQkJOnnypKtOcXGxHn/8ce3fv1+FhYW6ePGiEhISdO7cObf+7r33XjmdTtdWUFDg7SkCAIAeymIYhuHNAePHj9fYsWOVk5PjKrvtttt0//33y+FwtKm/du1a5eTk6JNPPnGVZWdna82aNTpx4oTHPlpaWtSvXz+tX79es2bN8ljn73//u0JDQ1VcXKx77rlH0qUVnzNnzuidd97x5pRc6uvrFRwcrLq6OvXt27dTbQAAgOvLm/dvr1Z8mpubVVpaqoSEBLfyhIQE7d271+MxcXFxqqqqUkFBgQzD0KlTp7RlyxYlJSW1209jY6MuXLig/v37t1unrq5OktrUKSoqUmhoqG699VbNmzdPNTU17bbR1NSk+vp6tw0AAPRcXgWf06dPq6WlRWFhYW7lYWFhqq6u9nhMXFyc8vLylJKSIl9fX9lsNoWEhCg7O7vdfpYuXapBgwZp6tSpHvcbhqGMjAzdfffdGj16tKs8MTFReXl52rlzp55//nmVlJRoypQpampq8tiOw+FQcHCwaxsyZMi1pgAAAHRjnfpws8VicXttGEabsssOHz6sRYsWadmyZSotLdW2bdtUUVGh+fPne6y/Zs0avfXWW8rPz1fv3r091lm4cKEOHjyot956y608JSVFSUlJGj16tJKTk/Xee+/p448/1tatWz22k5mZqbq6OtfW3q03AADQM9zkTeUBAwbIarW2Wd2pqalpswp0mcPh0MSJE7VkyRJJUlRUlAIDAxUfH69Vq1bJbre76q5du1arV6/Wjh07FBUV5bG9X/ziF3r33Xf14YcfavDgwVcdr91uV0REhI4dO+Zxv5+fn/z8/K7aBgAA6Dm8WvHx9fVVTEyMCgsL3coLCwsVFxfn8ZjGxkb5+Lh3Y7VaJV1aKbrsueee09NPP61t27YpNja2TTuGYWjhwoXKz8/Xzp07FRkZec3x1tbW6sSJE27hCgAAmJfXt7oyMjL0hz/8Qa+++qqOHDmif/mXf1FlZaXr1lVmZqbbN7GSk5OVn5+vnJwcffrpp/rv//5vLVq0SOPGjVN4eLikS7e3/u3f/k2vvvqqhg0bpurqalVXV+vs2bOudh5//HG98cYbevPNNxUUFOSq8+WXX0qSzp49qyeeeEL79u3T8ePHVVRUpOTkZA0YMEAPPPDA15okAADQQxid8Pvf/96IiIgwfH19jbFjxxrFxcWufbNnzzYmTZrkVv+FF14wRo0aZfj7+xt2u9145JFHjKqqKtf+iIgIQ1Kbbfny5a46nvZLMjZu3GgYhmE0NjYaCQkJxsCBA41evXoZQ4cONWbPnm1UVlZ2+Lzq6uoMSUZdXV1npgUAAHQBb96/vX6OT0/Gc3wAAOh+vrXn+AAAAHRnBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAaBB8AAGAanQo+GzZsUGRkpHr37q2YmBjt3r37qvXz8vIUHR2tgIAA2e12paWlqba21rX/5ZdfVnx8vPr166d+/fpp6tSp+uijj7zu1zAMrVixQuHh4fL399fkyZNVXl7emVMEAAA9kNfBZ9OmTUpPT1dWVpbKysoUHx+vxMREVVZWeqy/Z88ezZo1S3PmzFF5ebk2b96skpISzZ0711WnqKhIM2bM0K5du7Rv3z4NHTpUCQkJOnnypFf9rlmzRuvWrdP69etVUlIim82madOmqaGhwdvTBAAAPZHhpXHjxhnz5893Kxs5cqSxdOlSj/Wfe+454+abb3Yre+GFF4zBgwe328fFixeNoKAg47XXXutwv62trYbNZjOeeeYZ1/7z588bwcHBxosvvtihc6urqzMkGXV1dR2qDwAAup43799erfg0NzertLRUCQkJbuUJCQnau3evx2Pi4uJUVVWlgoICGYahU6dOacuWLUpKSmq3n8bGRl24cEH9+/fvcL8VFRWqrq52q+Pn56dJkya1O7ampibV19e7bQAAoOfyKvicPn1aLS0tCgsLcysPCwtTdXW1x2Pi4uKUl5enlJQU+fr6ymazKSQkRNnZ2e32s3TpUg0aNEhTp07tcL+X//VmbA6HQ8HBwa5tyJAhVzl7AADQ3XXqw80Wi8XttWEYbcouO3z4sBYtWqRly5aptLRU27ZtU0VFhebPn++x/po1a/TWW28pPz9fvXv39rpfb8aWmZmpuro613bixAmP9QAAQM9wkzeVBwwYIKvV2mYFpaamps1Ky2UOh0MTJ07UkiVLJElRUVEKDAxUfHy8Vq1aJbvd7qq7du1arV69Wjt27FBUVJRX/dpsNkmXVn6ubPNqY/Pz85Ofn19HTx8AAHRzXq34+Pr6KiYmRoWFhW7lhYWFiouL83hMY2OjfHzcu7FarZIurcZc9txzz+npp5/Wtm3bFBsb63W/kZGRstlsbnWam5tVXFzc7tgAAIC5eLXiI0kZGRl69NFHFRsbqwkTJuill15SZWWl69ZVZmamTp48qdzcXElScnKy5s2bp5ycHE2fPl1Op1Pp6ekaN26cwsPDJV26vfXLX/5Sb775poYNG+Za2enTp4/69OnToX4tFovS09O1evVqjRgxQiNGjNDq1asVEBCgmTNnfv2ZAgAA3V9nvjb2+9//3oiIiDB8fX2NsWPHGsXFxa59s2fPNiZNmuRW/4UXXjBGjRpl+Pv7G3a73XjkkUeMqqoq1/6IiAhDUptt+fLlHe7XMC59pX358uWGzWYz/Pz8jHvuucc4dOhQh8+Lr7MDAND9ePP+bTGMK+43mVx9fb2Cg4NVV1envn37dvVwAABAB3jz/s1vdQEAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANMg+AAAANO4qasHYAqGIV1o7OpRAABwY+gVIFksXdI1wed6uNAorQ7v6lEAAHBjeOpzyTewS7rmVhcAADANVnyuh14Bl9ItAAC49L7YRQg+14PF0mVLegAA4B+41QUAAEyD4AMAAEyD4AMAAEyD4AMAAEyD4AMAAEyD4AMAAEyD4AMAAEyD4AMAAEyD4AMAAEyD4AMAAEyD4AMAAEyD4AMAAEyD4AMAAEyDX2e/gmEYkqT6+vouHgkAAOioy+/bl9/Hr4bgc4WGhgZJ0pAhQ7p4JAAAwFsNDQ0KDg6+ah2L0ZF4ZBKtra36/PPPFRQUJIvF4ravvr5eQ4YM0YkTJ9S3b98uGmH3w7x1DvPWOcyb95izzmHeOufbmjfDMNTQ0KDw8HD5+Fz9Uzys+FzBx8dHgwcPvmqdvn37cpF3AvPWOcxb5zBv3mPOOod565xvY96utdJzGR9uBgAApkHwAQAApkHw6SA/Pz8tX75cfn5+XT2UboV56xzmrXOYN+8xZ53DvHXOjTBvfLgZAACYBis+AADANAg+AADANAg+AADANAg+AADANAg+HbRhwwZFRkaqd+/eiomJ0e7du7t6SDe0FStWyGKxuG02m62rh3XD+fDDD5WcnKzw8HBZLBa98847bvsNw9CKFSsUHh4uf39/TZ48WeXl5V0z2BvEteYsNTW1zbV31113dc1gbyAOh0N33nmngoKCFBoaqvvvv19Hjx51q8P15q4jc8b11lZOTo6ioqJcDymcMGGC3nvvPdf+rr7OCD4dsGnTJqWnpysrK0tlZWWKj49XYmKiKisru3poN7Tbb79dTqfTtR06dKirh3TDOXfunKKjo7V+/XqP+9esWaN169Zp/fr1Kikpkc1m07Rp01y/K2dG15ozSbr33nvdrr2CgoLrOMIbU3FxsR5//HHt379fhYWFunjxohISEnTu3DlXHa43dx2ZM4nr7asGDx6sZ555Rn/5y1/0l7/8RVOmTNF9993nCjddfp0ZuKZx48YZ8+fPdysbOXKksXTp0i4a0Y1v+fLlRnR0dFcPo1uRZLz99tuu162trYbNZjOeeeYZV9n58+eN4OBg48UXX+yCEd54vjpnhmEYs2fPNu67774uGU93UlNTY0gyiouLDcPgeuuIr86ZYXC9dVS/fv2MP/zhDzfEdcaKzzU0NzertLRUCQkJbuUJCQnau3dvF42qezh27JjCw8MVGRmphx9+WJ9++mlXD6lbqaioUHV1tdu15+fnp0mTJnHtXUNRUZFCQ0N16623at68eaqpqenqId1w6urqJEn9+/eXxPXWEV+ds8u43trX0tKiP/7xjzp37pwmTJhwQ1xnBJ9rOH36tFpaWhQWFuZWHhYWpurq6i4a1Y1v/Pjxys3N1fbt2/Xyyy+rurpacXFxqq2t7eqhdRuXry+uPe8kJiYqLy9PO3fu1PPPP6+SkhJNmTJFTU1NXT20G4ZhGMrIyNDdd9+t0aNHS+J6uxZPcyZxvbXn0KFD6tOnj/z8/DR//ny9/fbbGjVq1A1xnfHr7B1ksVjcXhuG0aYM/5CYmOj6+4477tCECRN0yy236LXXXlNGRkYXjqz74drzTkpKiuvv0aNHKzY2VhEREdq6dat+8pOfdOHIbhwLFy7UwYMHtWfPnjb7uN48a2/OuN48++53v6sDBw7ozJkz+tOf/qTZs2eruLjYtb8rrzNWfK5hwIABslqtbZJoTU1Nm8SK9gUGBuqOO+7QsWPHunoo3cblb8Fx7X09drtdERERXHv/3y9+8Qu9++672rVrlwYPHuwq53prX3tz5gnX2yW+vr4aPny4YmNj5XA4FB0drd/97nc3xHVG8LkGX19fxcTEqLCw0K28sLBQcXFxXTSq7qepqUlHjhyR3W7v6qF0G5GRkbLZbG7XXnNzs4qLi7n2vFBbW6sTJ06Y/tozDEMLFy5Ufn6+du7cqcjISLf9XG9tXWvOPOF688wwDDU1Nd0Y19l1+Qh1N/fHP/7R6NWrl/HKK68Yhw8fNtLT043AwEDj+PHjXT20G9bixYuNoqIi49NPPzX2799v/OhHPzKCgoKYs69oaGgwysrKjLKyMkOSsW7dOqOsrMz47LPPDMMwjGeeecYIDg428vPzjUOHDhkzZsww7Ha7UV9f38Uj7zpXm7OGhgZj8eLFxt69e42Kigpj165dxoQJE4xBgwaZes4MwzB+/vOfG8HBwUZRUZHhdDpdW2Njo6sO15u7a80Z15tnmZmZxocffmhUVFQYBw8eNJ566inDx8fHeP/99w3D6PrrjODTQb///e+NiIgIw9fX1xg7dqzb1xnRVkpKimG3241evXoZ4eHhxk9+8hOjvLy8q4d1w9m1a5chqc02e/ZswzAufcV4+fLlhs1mM/z8/Ix77rnHOHToUNcOuotdbc4aGxuNhIQEY+DAgUavXr2MoUOHGrNnzzYqKyu7ethdztOcSTI2btzoqsP15u5ac8b15tljjz3mer8cOHCg8YMf/MAVegyj668zi2EYxvVZWwIAAOhafMYHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYBsEHAACYxv8DTdkF1zn+HsoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_train=[]\n",
    "score_valid=[]\n",
    "params=[1,5,10,20,30]\n",
    "for n in params:\n",
    "    model = MyDecisionTreeClassifier(min_samples_split=2, max_depth=n, criterion='log_loss')\n",
    "    model.fit(X_train, y_train)\n",
    "    score_train.append(accuracy_score(y_pred=model.predict(X_train), y_true=y_train))\n",
    "    score_valid.append(accuracy_score(y_pred=model.predict(X_test), y_true=y_test))\n",
    "plt.plot(params, score_train, label='train')\n",
    "plt.plot(params, score_valid, label='valid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "score_train=[]\n",
    "score_valid=[]\n",
    "params=[1,5,10,20,30]\n",
    "for n in params:\n",
    "    model = MyDecisionTreeClassifier(min_samples_split=n, max_depth=5, criterion='log_loss')\n",
    "    model.fit(X_train, y_train)\n",
    "    score_train.append(accuracy_score(y_pred=model.predict(X_train), y_true=y_train))\n",
    "    score_valid.append(accuracy_score(y_pred=model.predict(X_test), y_true=y_test))\n",
    "plt.plot(params, score_train, label='train')\n",
    "plt.plot(params, score_valid, label='valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8386123680241327"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(*score_train, *score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная достигнутая точность на валидации - 83.90%. Наилучший критерий информативности, подобранный на валидации - критерий log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известным фактом является то, что деревья решений сильно переобучаются при увеличении глубины и просто запоминают трейн. \n",
    "Замечаете ли вы такой эффект судя по графикам? Что при этом происходит с качеством на валидации? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по валидации, при увеличении глубины деревья действительно переобучаются. Качество на тренировочном датасете растёт, а на валидационном - падает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Находим самые важные признаки (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший. \n",
    "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
    "Выведите 10 главных фичей по важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attr1_1',\n",
       " 'fun3_1',\n",
       " 'sinc3_1',\n",
       " 'attr3_1',\n",
       " 'shar2_1',\n",
       " 'amb2_1',\n",
       " 'fun2_1',\n",
       " 'intel2_1',\n",
       " 'sinc2_1',\n",
       " 'attr2_1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyDecisionTreeClassifier(min_samples_split=20, max_depth=20, criterion='log_loss')\n",
    "model.fit(X_train, y_train)\n",
    "[df_X.columns[j] for j in model.get_feature_importance().argsort()][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?\n",
    "Самое непонятное - как реализовать быстрый fit. Я, вроде, свёл время к O(N\\*log(N)) когда различных значений признака немного, и O(N^2) в худшем случае, и всё равно медленно. Не очень понятно, что ещё можно оптимизировать, если проводить полный перебор по признакам и порогам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
